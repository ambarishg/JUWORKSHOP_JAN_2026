{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import qdrant_client.http.models as qmodels\n",
    "from config_qdrant import *\n",
    "from qdrant_client import QdrantClient\n",
    "from pprint import pprint\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafd254",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=HOST,\n",
    "    api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11095c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user question\n",
    "user_question = \"cute gray fuzzy bee\"\n",
    "COLLECTION_NAME =\"BEES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = AIProjectClient(\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "client = project.get_openai_client(api_version=\"2024-10-21\")\n",
    "\n",
    "MODEL_NAME = AZURE_OPENAI_DEPLOYMENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94c0a8",
   "metadata": {},
   "source": [
    "### RAG without Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = client.embeddings.create(model=\"text-embedding-3-small\", input=user_question).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant_client.query_points(collection_name=COLLECTION_NAME,\n",
    "                                        query=query_vector, \n",
    "                                        query_filter=None,\n",
    "                                        limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scored_point in search_result.points:\n",
    "    context = context + \" \" + (scored_point.payload[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the matches to generate a response\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that answers questions about insects.\n",
    "You must use the data set to answer the questions,\n",
    "you should not provide any info that is not in the provided sources.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.3,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_question}\\nSources: {context}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"\\nResponse from {MODEL_NAME} on : \\n\")\n",
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530c8a6",
   "metadata": {},
   "source": [
    "### ReRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e16ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(query, retrieved_documents):\n",
    "    \"\"\"\n",
    "    Rerank the results using a cross-encoder model.\n",
    "    \"\"\"\n",
    "    encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    scores = encoder.predict([(query, doc.payload[\"content\"]) for doc in retrieved_documents])\n",
    "    scored_documents = [v for _, v in sorted(zip(scores, retrieved_documents), reverse=True)]\n",
    "    return scored_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27392a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_results = rerank(user_question, search_result.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3811250",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =\"\"\n",
    "for scored_point in reranked_results:\n",
    "    context = context + \" \" + (scored_point.payload[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba19100",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the matches to generate a response\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that answers questions about insects.\n",
    "You must use the data set to answer the questions,\n",
    "you should not provide any info that is not in the provided sources.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.3,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_question}\\nSources: {context}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"\\nResponse from {MODEL_NAME} on : \\n\")\n",
    "pprint(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
